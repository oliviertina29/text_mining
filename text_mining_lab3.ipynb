{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recuperation du vocabulaire du corpus\n",
    "vocabulaire=reuters.words()\n",
    "\n",
    "#recuperation de toutes les categories\n",
    "categories=reuters.categories()\n",
    "\n",
    "#recuperation de tous les id des fichiers appartenant à une categorie bien determinée\n",
    "ids_coffe=reuters.fileids(\"coffee\")\n",
    "\n",
    "#recuperation des mots contenus dans les documents d'une categorie bien determinee\n",
    "coffe_words=reuters.words(reuters.fileids(\"coffee\"))\n",
    "\n",
    "#recuperation du texte brut des documents d'une categorie bien determinee\n",
    "cofee_docs=reuters.raw(reuters.fileids(\"coffee\")[0])\n",
    "\n",
    "#recuperation de toutes les autres classe d'un document annoté avec une classe bien determinee\n",
    "classes_Annotated_coffee=reuters.categories(reuters.fileids(\"coffee\"))\n",
    "\n",
    "#recuperer le dataset d'apprentissage\n",
    "train_categories=[ reuters.categories(i) for i in reuters.fileids() if i.startswith('training/')]\n",
    "train_documents = [reuters.raw(i) for i in reuters.fileids() if i.startswith('training/')]\n",
    "\n",
    "#recuperer le dataset de test\n",
    "test_documents=[reuters.raw(i)  for i in reuters.fileids() if i.startswith('test/')]\n",
    "test_categories = [reuters.categories(i) for i in reuters.fileids() if i.startswith('test/')]\n",
    "\n",
    "# recuperer tout le corpus\n",
    "whole_docs=[reuters.raw(i)for i in reuters.fileids()]\n",
    "whole_cats = [ reuters.categories(i) for i in reuters.fileids()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' ... 'zy' 'zzzz' 'üside']\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.07837603 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.18232755 0.         ... 0.         0.         0.        ]]\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.06296253 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "#Generer le vocabulaire à partir du whole_docs\n",
    "#Realiser les differentes operations NLP permettant d'unifier la representation\n",
    "#vectorielle de tout le corpus\n",
    "\n",
    "#whole_docs=.........\n",
    "vect_whole_docs = vectorizer.fit_transform(whole_docs)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "#vectoriser les datasets d'apprentissage et de test\n",
    "vect_train_docs = vectorizer.transform(train_documents)\n",
    "vect_test_docs = vectorizer.transform(test_documents)\n",
    "print(vect_train_docs.toarray())\n",
    "print(vect_test_docs.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq' 'alum' 'barley' 'bop' 'carcass' 'castor-oil' 'cocoa' 'coconut'\n",
      " 'coconut-oil' 'coffee' 'copper' 'copra-cake' 'corn' 'cotton' 'cotton-oil'\n",
      " 'cpi' 'cpu' 'crude' 'dfl' 'dlr' 'dmk' 'earn' 'fuel' 'gas' 'gnp' 'gold'\n",
      " 'grain' 'groundnut' 'groundnut-oil' 'heat' 'hog' 'housing' 'income'\n",
      " 'instal-debt' 'interest' 'ipi' 'iron-steel' 'jet' 'jobs' 'l-cattle'\n",
      " 'lead' 'lei' 'lin-oil' 'livestock' 'lumber' 'meal-feed' 'money-fx'\n",
      " 'money-supply' 'naphtha' 'nat-gas' 'nickel' 'nkr' 'nzdlr' 'oat' 'oilseed'\n",
      " 'orange' 'palladium' 'palm-oil' 'palmkernel' 'pet-chem' 'platinum'\n",
      " 'potato' 'propane' 'rand' 'rape-oil' 'rapeseed' 'reserves' 'retail'\n",
      " 'rice' 'rubber' 'rye' 'ship' 'silver' 'sorghum' 'soy-meal' 'soy-oil'\n",
      " 'soybean' 'strategic-metal' 'sugar' 'sun-meal' 'sun-oil' 'sunseed' 'tea'\n",
      " 'tin' 'trade' 'veg-oil' 'wheat' 'wpi' 'yen' 'zinc']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#recuperer des labels uniques pour les categories\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "train_labels = mlb.fit_transform(train_categories)\n",
    "test_labels = mlb.transform(test_categories)\n",
    "whole_labels = mlb.fit_transform(whole_cats)\n",
    "\n",
    "print(mlb.classes_)\n",
    "print(whole_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       719\n",
      "           1       1.00      0.43      0.61        23\n",
      "           2       1.00      0.64      0.78        14\n",
      "           3       0.95      0.60      0.73        30\n",
      "           4       0.88      0.39      0.54        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.94      0.97        18\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.96      0.96      0.96        28\n",
      "          10       1.00      0.78      0.88        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.95      0.71      0.82        56\n",
      "          13       1.00      0.50      0.67        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.92      0.43      0.59        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.91      0.81      0.86       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.85      0.66      0.74        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.98      0.99      1087\n",
      "          22       1.00      0.20      0.33        10\n",
      "          23       1.00      0.53      0.69        17\n",
      "          24       1.00      0.80      0.89        35\n",
      "          25       0.92      0.73      0.81        30\n",
      "          26       0.98      0.81      0.89       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       1.00      0.75      0.86         4\n",
      "          32       1.00      0.43      0.60         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.88      0.66      0.75       131\n",
      "          35       1.00      0.83      0.91        12\n",
      "          36       0.75      0.64      0.69        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.92      0.57      0.71        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.69      0.38      0.49        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       1.00      0.16      0.27        19\n",
      "          46       0.81      0.73      0.76       179\n",
      "          47       0.89      0.74      0.81        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.74      0.47      0.57        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       1.00      0.17      0.29         6\n",
      "          54       0.79      0.47      0.59        47\n",
      "          55       1.00      0.45      0.62        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.60      0.75        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       1.00      0.33      0.50         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       0.91      0.56      0.69        18\n",
      "          67       1.00      0.50      0.67         2\n",
      "          68       0.88      0.29      0.44        24\n",
      "          69       1.00      0.75      0.86        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.89      0.63      0.74        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.75      0.30      0.43        10\n",
      "          74       1.00      0.15      0.27        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.83      0.45      0.59        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.96      0.72      0.83        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       1.00      0.20      0.33         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.58      0.74        12\n",
      "          84       0.87      0.75      0.81       117\n",
      "          85       0.94      0.43      0.59        37\n",
      "          86       0.93      0.75      0.83        71\n",
      "          87       1.00      0.60      0.75        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       1.00      0.46      0.63        13\n",
      "\n",
      "   micro avg       0.95      0.78      0.86      3744\n",
      "   macro avg       0.59      0.36      0.43      3744\n",
      "weighted avg       0.91      0.78      0.83      3744\n",
      " samples avg       0.87      0.85      0.86      3744\n",
      "\n",
      "SVM score :0.8042398145081153\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "classifier_svm = OneVsRestClassifier(LinearSVC())\n",
    "classifier_svm.fit(vect_train_docs,train_labels)\n",
    "test_labels_predict=classifier_svm.predict(vect_test_docs)\n",
    "print(classification_report(test_labels,test_labels_predict))\n",
    "scores=classifier_svm.score(vect_test_docs,test_labels)\n",
    "print(\"SVM score :{}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM avec validation croisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.38013768 2.552423   2.14042521]\n",
      "[0.2086215  0.17915845 0.16136146]\n",
      "[0.86598999 0.87977382 0.88399611]\n",
      "[0.84546102 0.86121606 0.86284829]\n",
      "[0.8475128  0.86216063 0.86600443]\n"
     ]
    }
   ],
   "source": [
    "# Classification SVM avec cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples']\n",
    "scores_svm = cross_validate(classifier_svm, vect_whole_docs, whole_labels, cv=3, scoring=scoring)\n",
    "print(scores_svm['fit_time'])\n",
    "print(scores_svm['score_time'])\n",
    "print(scores_svm['test_precision_samples'])\n",
    "print(scores_svm['test_recall_samples'])\n",
    "print(scores_svm['test_f1_samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f636204ce00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f636204ce00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/olivier/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.80       719\n",
      "           1       0.77      0.43      0.56        23\n",
      "           2       0.86      0.43      0.57        14\n",
      "           3       0.62      0.53      0.57        30\n",
      "           4       0.73      0.61      0.67        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.94      0.97        18\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.83      0.89      0.86        28\n",
      "          10       0.74      0.78      0.76        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.70      0.59      0.64        56\n",
      "          13       0.82      0.45      0.58        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.82      0.50      0.62        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.81      0.89      0.85       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.73      0.68      0.71        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.88      0.96      0.92      1087\n",
      "          22       0.50      0.20      0.29        10\n",
      "          23       1.00      0.41      0.58        17\n",
      "          24       0.81      0.71      0.76        35\n",
      "          25       0.91      0.67      0.77        30\n",
      "          26       0.83      0.80      0.82       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.50      0.67         6\n",
      "          31       0.50      0.75      0.60         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       0.81      0.69      0.75       131\n",
      "          35       1.00      0.83      0.91        12\n",
      "          36       0.92      0.79      0.85        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.52      0.69        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       1.00      0.14      0.25        14\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.71      0.71      0.71        24\n",
      "          44       1.00      0.17      0.29         6\n",
      "          45       0.75      0.16      0.26        19\n",
      "          46       0.72      0.84      0.78       179\n",
      "          47       0.74      0.82      0.78        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.75      0.50      0.60        30\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.64      0.34      0.44        47\n",
      "          55       1.00      0.64      0.78        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.88      0.70      0.78        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       1.00      0.08      0.15        12\n",
      "          60       1.00      0.29      0.44         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       0.67      0.44      0.53        18\n",
      "          67       1.00      0.50      0.67         2\n",
      "          68       0.50      0.08      0.14        24\n",
      "          69       0.82      0.75      0.78        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.76      0.74      0.75        89\n",
      "          72       0.67      0.25      0.36         8\n",
      "          73       0.25      0.10      0.14        10\n",
      "          74       1.00      0.08      0.14        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.75      0.36      0.49        33\n",
      "          77       1.00      0.09      0.17        11\n",
      "          78       0.96      0.72      0.83        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.50      0.20      0.29         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.75      0.86        12\n",
      "          84       0.70      0.67      0.68       117\n",
      "          85       0.72      0.49      0.58        37\n",
      "          86       0.62      0.75      0.68        71\n",
      "          87       1.00      0.60      0.75        10\n",
      "          88       0.60      0.21      0.32        14\n",
      "          89       1.00      0.31      0.47        13\n",
      "\n",
      "   micro avg       0.84      0.74      0.78      3744\n",
      "   macro avg       0.57      0.39      0.43      3744\n",
      "weighted avg       0.82      0.74      0.76      3744\n",
      " samples avg       0.80      0.80      0.79      3744\n",
      "\n",
      "KNN Score: 0.7287181185823121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier_knn = KNeighborsClassifier()\n",
    "classifier_knn.fit(vect_train_docs, train_labels)\n",
    "test_labels_predict_knn = classifier_knn.predict(vect_test_docs)\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(test_labels, test_labels_predict_knn))\n",
    "\n",
    "scores_knn = classifier_knn.score(vect_test_docs, test_labels)\n",
    "print(\"KNN Score: {}\".format(scores_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scores_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       719\n",
      "           1       1.00      0.04      0.08        23\n",
      "           2       1.00      0.07      0.13        14\n",
      "           3       1.00      0.07      0.12        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       1.00      0.21      0.35        28\n",
      "          10       1.00      0.11      0.20        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      0.23      0.38        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.67      0.07      0.13        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       1.00      0.41      0.58       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.94      0.39      0.55        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.97      0.98      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       1.00      0.12      0.21        17\n",
      "          24       0.00      0.00      0.00        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       0.95      0.52      0.67       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.20      0.33         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.91      0.38      0.54       131\n",
      "          35       1.00      0.08      0.15        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.10      0.17        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       1.00      0.12      0.22        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.79      0.40      0.53       179\n",
      "          47       0.88      0.44      0.59        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       1.00      0.17      0.29         6\n",
      "          54       0.90      0.19      0.32        47\n",
      "          55       1.00      0.09      0.17        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.33      0.50         9\n",
      "          66       1.00      0.06      0.11        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.86      0.13      0.23        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       1.00      0.10      0.18        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       1.00      0.09      0.17        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       1.00      0.22      0.36        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.97      0.31      0.47       117\n",
      "          85       1.00      0.03      0.05        37\n",
      "          86       0.91      0.30      0.45        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.97      0.58      0.73      3744\n",
      "   macro avg       0.35      0.09      0.13      3744\n",
      "weighted avg       0.84      0.58      0.64      3744\n",
      " samples avg       0.69      0.67      0.68      3744\n",
      "\n",
      "Ensemble Score: 0.6538588936734018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_ensemble = RandomForestClassifier()\n",
    "classifier_ensemble.fit(vect_train_docs, train_labels)\n",
    "test_labels_predict_ensemble = classifier_ensemble.predict(vect_test_docs)\n",
    "\n",
    "print(\"Ensemble Classification Report:\")\n",
    "print(classification_report(test_labels, test_labels_predict_ensemble))\n",
    "\n",
    "scores_ensemble = classifier_ensemble.score(vect_test_docs, test_labels)\n",
    "print(\"Ensemble Score: {}\".format(scores_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       719\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00        17\n",
      "          24       0.00      0.00      0.00        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       0.00      0.00      0.00       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00       131\n",
      "          35       0.00      0.00      0.00        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.00      0.00      0.00       179\n",
      "          47       0.00      0.00      0.00        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00        47\n",
      "          55       0.00      0.00      0.00        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         9\n",
      "          66       0.00      0.00      0.00        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.00      0.00      0.00        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.00      0.00      0.00        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.00      0.00      0.00       117\n",
      "          85       0.00      0.00      0.00        37\n",
      "          86       0.00      0.00      0.00        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      3744\n",
      "   macro avg       0.00      0.00      0.00      3744\n",
      "weighted avg       0.00      0.00      0.00      3744\n",
      " samples avg       0.00      0.00      0.00      3744\n",
      "\n",
      "MLP Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier_mlp = MLPClassifier(activation='logistic', solver='sgd')\n",
    "classifier_mlp.fit(vect_train_docs, train_labels)\n",
    "test_labels_predict_mlp = classifier_mlp.predict(vect_test_docs)\n",
    "\n",
    "print(\"MLP Classification Report:\")\n",
    "print(classification_report(test_labels, test_labels_predict_mlp))\n",
    "\n",
    "scores_mlp = classifier_mlp.score(vect_test_docs, test_labels)\n",
    "print(\"MLP Score: {}\".format(scores_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scores_svm = scores_svm\\nscores_knn = scores_knn\\nscores_ensemble = scores_ensemble\\nscores_mlp = scores_mlp'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_svm = scores_svm\n",
    "scores_knn = scores_knn\n",
    "scores_ensemble = scores_ensemble\n",
    "scores_mlp = scores_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_scores = [scores_svm, scores_knn, scores_ensemble, scores_mlp]\n",
    "\n",
    "# Noms des modèles\n",
    "model_names = ['SVM', 'KNN', 'Ensemble', 'MLP']\n",
    "\n",
    "# Créer un graphique comparatif\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, list_scores, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.title('Scores des modèles comparatifs')\n",
    "plt.xlabel('Modèles')\n",
    "plt.ylabel('Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature selection SelectKBest de la librairie sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Feature Selection:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       719\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00        17\n",
      "          24       0.00      0.00      0.00        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       0.97      0.40      0.56       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00       131\n",
      "          35       0.00      0.00      0.00        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.00      0.00      0.00       179\n",
      "          47       0.00      0.00      0.00        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00        47\n",
      "          55       0.00      0.00      0.00        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.60      0.75        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       1.00      0.14      0.25         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         9\n",
      "          66       0.00      0.00      0.00        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.00      0.00      0.00        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.00      0.00      0.00        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.00      0.00      0.00       117\n",
      "          85       1.00      0.16      0.28        37\n",
      "          86       0.98      0.68      0.80        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.96      0.03      0.06      3744\n",
      "   macro avg       0.07      0.03      0.04      3744\n",
      "weighted avg       0.07      0.03      0.04      3744\n",
      " samples avg       0.02      0.02      0.02      3744\n",
      "\n",
      "Score with Feature Selection: 0.011262007287181186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Apply SelectKBest for feature selection\n",
    "k_best = SelectKBest(chi2, k=10) \n",
    "\n",
    "vect_train_docs_selected = k_best.fit_transform(vect_train_docs, train_labels)\n",
    "vect_test_docs_selected = k_best.transform(vect_test_docs)\n",
    "\n",
    "# Train and test a classifier on the selected features\n",
    "classifier_selected = OneVsRestClassifier(LinearSVC())\n",
    "classifier_selected.fit(vect_train_docs_selected, train_labels)\n",
    "test_labels_predict_selected = classifier_selected.predict(vect_test_docs_selected)\n",
    "\n",
    "print(\"Classification Report with Feature Selection:\")\n",
    "print(classification_report(test_labels, test_labels_predict_selected))\n",
    "\n",
    "scores_selected = classifier_selected.score(vect_test_docs_selected, test_labels)\n",
    "print(\"Score with Feature Selection: {}\".format(scores_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
