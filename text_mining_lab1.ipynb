{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TINA Djara Olivier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.wsd import lesk\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/olivier/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assurez-vous d'avoir téléchargé WordNet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Constituer le contexte du document en recuperant tous les termes sigfificatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constituer_contexte(texte):\n",
    "    # Tokenisation des mots\n",
    "    mots = word_tokenize(texte)\n",
    "    \n",
    "    # Suppression des mots vides (stop words)\n",
    "    mots = [mot.lower() for mot in mots if mot.isalnum() and mot.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Identification des noms et des entités importantes (sujet, verbe, adjectif, etc.)\n",
    "    termes_significatifs = [mot for mot, pos in pos_tag(mots) if pos.startswith('N') or pos.startswith('V') or pos.startswith('J')]\n",
    "\n",
    "    return termes_significatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'learning', 'subfield', 'artificial', 'intelligence', 'focuses', 'development', 'statistical', 'models', 'computers', 'use', 'perform', 'specific', 'task', 'using', 'explicit', 'instructions', 'natural', 'language', 'processing', 'nlp', 'essential', 'component', 'machine', 'learning', 'enabling', 'computers', 'understand', 'interpret', 'generate', 'language']\n"
     ]
    }
   ],
   "source": [
    "texte_anglais = \"Machine learning is a subfield of artificial intelligence that focuses on the development of algorithms and statistical models that computers use to perform a specific task without using explicit instructions. Natural Language Processing (NLP) is an essential component of machine learning, enabling computers to understand, interpret, and generate human-like language.\"\n",
    "\n",
    "contexte = constituer_contexte(texte_anglais)\n",
    "print(contexte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Découper le texte en des phrases simples et recuperer les tags de leurs mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decouper_et_taguer(texte):\n",
    "    # Tokenisation en phrases\n",
    "    phrases = nltk.sent_tokenize(texte)\n",
    "\n",
    "    # Tokenisation des mots et étiquetage grammatical pour chaque phrase\n",
    "    phrases_taguees = [nltk.pos_tag(nltk.word_tokenize(phrase)) for phrase in phrases]\n",
    "\n",
    "    return phrases_taguees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase 1: [('Machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('that', 'WDT'), ('focuses', 'VBZ'), ('on', 'IN'), ('the', 'DT'), ('development', 'NN'), ('of', 'IN'), ('algorithms', 'NN'), ('and', 'CC'), ('statistical', 'JJ'), ('models', 'NNS'), ('that', 'IN'), ('computers', 'NNS'), ('use', 'VBP'), ('to', 'TO'), ('perform', 'VB'), ('a', 'DT'), ('specific', 'JJ'), ('task', 'NN'), ('without', 'IN'), ('using', 'VBG'), ('explicit', 'JJ'), ('instructions', 'NNS'), ('.', '.')]\n",
      "Phrase 2: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('essential', 'JJ'), ('component', 'NN'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('enabling', 'VBG'), ('computers', 'NNS'), ('to', 'TO'), ('understand', 'VB'), (',', ','), ('interpret', 'VB'), (',', ','), ('and', 'CC'), ('generate', 'VB'), ('human-like', 'JJ'), ('language', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "resultat = decouper_et_taguer(texte_anglais)\n",
    "\n",
    "# Affichage du résultat\n",
    "for i, phrase_taguee in enumerate(resultat, 1):\n",
    "    print(f\"Phrase {i}: {phrase_taguee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pour chaque phrase récuperer le sens exacte de chaque terme en se basant sur leurs Tags et leur contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperer_sens_exact(phrases_taguees):\n",
    "    resultats = []\n",
    "\n",
    "    for phrase_taguee in phrases_taguees:\n",
    "        phrase_resultat = []\n",
    "\n",
    "        for mot, tag in phrase_taguee:\n",
    "\n",
    "            try:\n",
    "                sens = lesk(phrase_taguee, mot)\n",
    "                if sens:\n",
    "                    definition = wordnet.synset(sens.name()).definition()\n",
    "                else:\n",
    "                    definition = \"Aucun sens trouvé\"\n",
    "            except:\n",
    "                definition = \"Erreur lors de la récupération du sens\"\n",
    "\n",
    "            phrase_resultat.append((mot, tag, definition))\n",
    "\n",
    "        resultats.append(phrase_resultat)\n",
    "\n",
    "    return resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat pour la phrase 1: [('Machine', 'NN', 'make by machinery'), ('learning', 'NN', 'impart skills or knowledge to'), ('is', 'VBZ', 'have an existence, be extant'), ('a', 'DT', 'any of several fat-soluble vitamins essential for normal vision; prevents night blindness or inflammation or dryness of the eyes'), ('subfield', 'NN', 'Aucun sens trouvé'), ('of', 'IN', 'Aucun sens trouvé'), ('artificial', 'JJ', 'not arising from natural growth or characterized by vital processes'), ('intelligence', 'NN', 'information about recent and important events'), ('that', 'WDT', 'Aucun sens trouvé'), ('focuses', 'VBZ', 'special emphasis attached to something'), ('on', 'IN', 'in a state required for something to function or be effective'), ('the', 'DT', 'Aucun sens trouvé'), ('development', 'NN', '(biology) the process of an individual organism growing organically; a purely biological unfolding of events involved in an organism changing gradually from a simple to a more complex level'), ('of', 'IN', 'Aucun sens trouvé'), ('algorithms', 'NN', 'a precise rule (or set of rules) specifying how to solve some problem'), ('and', 'CC', 'Aucun sens trouvé'), ('statistical', 'JJ', 'of or relating to statistics'), ('models', 'NNS', 'construct a model of'), ('that', 'IN', 'Aucun sens trouvé'), ('computers', 'NNS', 'a machine for performing calculations automatically'), ('use', 'VBP', 'habitually do something (use only in the past tense)'), ('to', 'TO', 'Aucun sens trouvé'), ('perform', 'VB', 'give a performance (of something)'), ('a', 'DT', 'any of several fat-soluble vitamins essential for normal vision; prevents night blindness or inflammation or dryness of the eyes'), ('specific', 'JJ', 'stated explicitly or in detail'), ('task', 'NN', 'any piece of work that is undertaken or attempted'), ('without', 'IN', 'Aucun sens trouvé'), ('using', 'VBG', 'habitually do something (use only in the past tense)'), ('explicit', 'JJ', 'precisely and clearly expressed or readily observable; leaving nothing to implication'), ('instructions', 'NNS', 'the profession of a teacher'), ('.', '.', 'Aucun sens trouvé')]\n",
      "Résultat pour la phrase 2: [('Natural', 'JJ', 'being talented through inherited qualities'), ('Language', 'NNP', 'a system of words used to name things in a particular discipline'), ('Processing', 'NNP', 'shape, form, or improve a material'), ('(', '(', 'Aucun sens trouvé'), ('NLP', 'NNP', 'the branch of information science that deals with natural language information'), (')', ')', 'Aucun sens trouvé'), ('is', 'VBZ', 'have an existence, be extant'), ('an', 'DT', 'an associate degree in nursing'), ('essential', 'JJ', 'defining rights and duties as opposed to giving the rules by which rights and duties are established'), ('component', 'NN', 'something determined in relation to something that includes it'), ('of', 'IN', 'Aucun sens trouvé'), ('machine', 'NN', 'make by machinery'), ('learning', 'NN', 'impart skills or knowledge to'), (',', ',', 'Aucun sens trouvé'), ('enabling', 'VBG', 'providing legal power or sanction'), ('computers', 'NNS', 'a machine for performing calculations automatically'), ('to', 'TO', 'Aucun sens trouvé'), ('understand', 'VB', 'believe to be the case'), (',', ',', 'Aucun sens trouvé'), ('interpret', 'VB', 'make sense of a language'), (',', ',', 'Aucun sens trouvé'), ('and', 'CC', 'Aucun sens trouvé'), ('generate', 'VB', 'give or supply'), ('human-like', 'JJ', 'Aucun sens trouvé'), ('language', 'NN', 'a system of words used to name things in a particular discipline'), ('.', '.', 'Aucun sens trouvé')]\n"
     ]
    }
   ],
   "source": [
    "phrases_taguees = decouper_et_taguer(texte_anglais)\n",
    "resultats = recuperer_sens_exact(phrases_taguees)\n",
    "\n",
    "# Affichage du résultat\n",
    "for i, phrase_resultat in enumerate(resultats, 1):\n",
    "    print(f\"Résultat pour la phrase {i}: {phrase_resultat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Récuperer les termes correspendant en francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduire_en_francais(mot):\n",
    "    try:\n",
    "        url = f\"https://api.mymemory.translated.net/get?q={mot}&langpair=en|fr\"\n",
    "        response = requests.get(url)\n",
    "        resultat_traduction = response.json()\n",
    "        \n",
    "        if \"responseData\" in resultat_traduction and \"translatedText\" in resultat_traduction[\"responseData\"]:\n",
    "            terme_francais = resultat_traduction[\"responseData\"][\"translatedText\"]\n",
    "            return terme_francais\n",
    "        else:\n",
    "            raise Exception(\"Erreur de traduction\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la traduction : {e}\")\n",
    "        return \"Erreur de traduction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pour chaque phrase afficher à l'utilisateur les propostions de traduction pour les nom, les adjectifs et les verbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperer_sens_exact(phrases_taguees):\n",
    "    resultats = []\n",
    "\n",
    "    for phrase_taguee in phrases_taguees:\n",
    "        phrase_resultat = []\n",
    "\n",
    "        for mot, tag in phrase_taguee:\n",
    "            # Utilisation de l'algorithme Lesk pour récupérer le sens du mot\n",
    "            try:\n",
    "                sens = lesk(phrase_taguee, mot)\n",
    "                if sens:\n",
    "                    definition = wordnet.synset(sens.name()).definition()\n",
    "                else:\n",
    "                    definition = \"Aucun sens trouvé\"\n",
    "            except:\n",
    "                definition = \"Erreur lors de la récupération du sens\"\n",
    "\n",
    "            # Traduire le terme en français\n",
    "            terme_francais = traduire_en_francais(mot)\n",
    "\n",
    "            phrase_resultat.append((mot, tag, terme_francais, definition))\n",
    "\n",
    "        resultats.append(phrase_resultat)\n",
    "\n",
    "    return resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat pour la phrase 1: [('Machine', 'NN', ['Machine', 'faire par machinerie'], 'make by machinery'), ('apprentissage', 'NN', ['apprentissage', 'transmettre des compétences ou des connaissances à'], 'impart skills or knowledge to'), ('is', 'VBZ', ['is', 'avoir une existence, être existant'], 'have an existence, be extant'), ('a', 'DT', [], 'any of several fat-soluble vitamins essential for normal vision; prevents night blindness or inflammation or dryness of the eyes'), ('sous-champ', 'NN', ['sous-champ', 'Aucun sens trouvé'], 'Aucun sens trouvé'), ('de', 'IN', [], 'Aucun sens trouvé'), ('gazon artificiel', 'JJ', ['gazon artificiel', \"ne résultant pas d'une croissance naturelle ou caractérisée par des processus vitaux\"], 'not arising from natural growth or characterized by vital processes'), ('renseignement;', 'NN', ['renseignement;', 'informations sur les événements récents et importants'], 'information about recent and important events'), ('cette', 'WDT', [], 'Aucun sens trouvé'), ('Se concentre', 'VBZ', ['Se concentre', 'accent particulier attaché à quelque chose'], 'special emphasis attached to something'), ('actif', 'IN', [], 'in a state required for something to function or be effective'), ('des', 'DT', [], 'Aucun sens trouvé'), ('développement', 'NN', ['développement', \"(biologie) le processus de croissance organique d'un organisme individuel\\xa0; un déroulement purement biologique d'événements impliqués dans un organisme passant progressivement d'un niveau simple à un niveau plus complexe\"], '(biology) the process of an individual organism growing organically; a purely biological unfolding of events involved in an organism changing gradually from a simple to a more complex level'), ('de', 'IN', [], 'Aucun sens trouvé'), (\"d'apprentissage automatique\", 'NN', [\"d'apprentissage automatique\", 'une règle précise (ou un ensemble de règles) spécifiant comment résoudre un problème'], 'a precise rule (or set of rules) specifying how to solve some problem'), ('et', 'CC', [], 'Aucun sens trouvé'), ('statistique', 'JJ', ['statistique', 'de ou en rapport avec les statistiques'], 'of or relating to statistics'), ('physiologiques', 'NNS', ['physiologiques', 'construire un modèle de'], 'construct a model of'), ('cette', 'IN', [], 'Aucun sens trouvé'), ('ordinateurs', 'NNS', ['ordinateurs', 'une machine pour effectuer des calculs automatiquement'], 'a machine for performing calculations automatically'), ('utilisations', 'VBP', ['utilisations', 'faire habituellement quelque chose (utiliser uniquement au passé)'], 'habitually do something (use only in the past tense)'), ('à', 'TO', [], 'Aucun sens trouvé'), ('réaliser', 'VB', ['réaliser', 'donner une performance (de quelque chose)'], 'give a performance (of something)'), ('a', 'DT', [], 'any of several fat-soluble vitamins essential for normal vision; prevents night blindness or inflammation or dryness of the eyes'), ('tâche connexe', 'JJ', ['tâche connexe', 'explicitement ou en détail'], 'stated explicitly or in detail'), ('prestation', 'NN', ['prestation', 'toute pièce de travail qui est entreprise ou tentée'], 'any piece of work that is undertaken or attempted'), ('sans', 'IN', [], 'Aucun sens trouvé'), ('utilisation', 'VBG', ['utilisation', 'faire habituellement quelque chose (utiliser uniquement au passé)'], 'habitually do something (use only in the past tense)'), ('explicit', 'JJ', ['explicit', \"précisément et clairement exprimé ou facilement observable\\xa0; ne laissant rien à l'implication\"], 'precisely and clearly expressed or readily observable; leaving nothing to implication'), ('instructions', 'NNS', ['instructions', \"la profession d'enseignant\"], 'the profession of a teacher'), ('.', '.', [], 'Aucun sens trouvé')]\n",
      "Résultat pour la phrase 2: [('Naturel', 'JJ', ['Naturel', 'être talentueux grâce à des qualités héritées'], 'being talented through inherited qualities'), ('Langue', 'NNP', ['Langue', 'un système de mots utilisé pour nommer des choses dans une discipline particulière'], 'a system of words used to name things in a particular discipline'), ('En cours', 'NNP', ['En cours', '- -'], 'shape, form, or improve a material'), ('(', '(', [], 'Aucun sens trouvé'), ('TLN', 'NNP', ['TLN', \"la branche des sciences de l'information qui traite de l'information en langage naturel\"], 'the branch of information science that deals with natural language information'), (')', ')', [], 'Aucun sens trouvé'), ('is', 'VBZ', ['is', 'avoir une existence, être existant'], 'have an existence, be extant'), ('un', 'DT', [], 'an associate degree in nursing'), ('essential', 'JJ', ['essential', 'définir les droits et les devoirs par opposition à donner les règles par lesquelles les droits et les devoirs sont établis'], 'defining rights and duties as opposed to giving the rules by which rights and duties are established'), ('composant', 'NN', ['composant', \"quelque chose de déterminé par rapport à quelque chose qui l'inclut\"], 'something determined in relation to something that includes it'), ('de', 'IN', [], 'Aucun sens trouvé'), ('machine', 'NN', ['machine', 'faire par machinerie'], 'make by machinery'), ('apprentissage', 'NN', ['apprentissage', 'transmettre des compétences ou des connaissances à'], 'impart skills or knowledge to'), (',', ',', [], 'Aucun sens trouvé'), ('permettant', 'VBG', ['permettant', 'fournir un pouvoir ou une sanction juridique'], 'providing legal power or sanction'), ('ordinateurs', 'NNS', ['ordinateurs', 'une machine pour effectuer des calculs automatiquement'], 'a machine for performing calculations automatically'), ('à', 'TO', [], 'Aucun sens trouvé'), ('comprendre', 'VB', ['comprendre', \"croient que c'est le cas\"], 'believe to be the case'), (',', ',', [], 'Aucun sens trouvé'), ('interpréter', 'VB', ['interpréter', '- -'], 'make sense of a language'), (',', ',', [], 'Aucun sens trouvé'), ('et', 'CC', [], 'Aucun sens trouvé'), ('générer', 'VB', ['générer', 'donner ou fournir'], 'give or supply'), (\"semblable à l'homme\", 'JJ', [\"semblable à l'homme\", 'Aucun sens trouvé'], 'Aucun sens trouvé'), ('langue', 'NN', ['langue', 'un système de mots utilisé pour nommer des choses dans une discipline particulière'], 'a system of words used to name things in a particular discipline'), ('.', '.', [], 'Aucun sens trouvé')]\n"
     ]
    }
   ],
   "source": [
    "phrases_taguees = decouper_et_taguer(texte_anglais)\n",
    "resultats = recuperer_sens_exact(phrases_taguees)\n",
    "\n",
    "# Affichage des résultats avec propositions de traduction\n",
    "for i, phrase_resultat in enumerate(resultats, 1):\n",
    "    phrase_traduite = []\n",
    "\n",
    "    for terme, tag, terme_francais, definition in phrase_resultat:\n",
    "        # Afficher les propositions de traduction pour les noms, adjectifs et verbes\n",
    "        if tag.startswith('N'):\n",
    "            traductions_proposees = [traduire_en_francais(terme) for terme in [terme, definition] if terme]\n",
    "        elif tag.startswith('J'):\n",
    "            traductions_proposees = [traduire_en_francais(terme) for terme in [terme, definition] if terme]\n",
    "        elif tag.startswith('V'):\n",
    "            traductions_proposees = [traduire_en_francais(terme) for terme in [terme, definition] if terme]\n",
    "        else:\n",
    "            traductions_proposees = []\n",
    "\n",
    "        phrase_traduite.append((terme_francais, tag, traductions_proposees, definition))\n",
    "\n",
    "    print(f\"Résultat pour la phrase {i}: {phrase_traduite}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : dection de plagiarisme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import Levenshtein\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texte original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier = \"plagitat_corpus/plagitat_corpus/original\"\n",
    "text_wikipedia = []\n",
    "\n",
    "fichiers_dans_dossier = os.listdir(dossier)\n",
    "\n",
    "for nom_fichier in fichiers_dans_dossier:\n",
    "    chemin_complet = os.path.join(dossier, nom_fichier)\n",
    "    if os.path.isfile(chemin_complet) and nom_fichier.endswith(\".txt\"):\n",
    "        with open(chemin_complet, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()\n",
    "            text_wikipedia.append(contenu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textes des étudiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier1 = \"plagitat_corpus/plagitat_corpus/PA\"\n",
    "PA = []\n",
    "\n",
    "fichiers_dans_dossier = os.listdir(dossier1)\n",
    "\n",
    "for nom_fichier in fichiers_dans_dossier:\n",
    "    chemin_complet = os.path.join(dossier1, nom_fichier)\n",
    "    if os.path.isfile(chemin_complet) and nom_fichier.endswith(\".txt\"):\n",
    "        with open(chemin_complet, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()\n",
    "            PA.append(contenu)\n",
    "\n",
    "\n",
    "dossier2 = \"plagitat_corpus/plagitat_corpus/PB\"\n",
    "PB = []\n",
    "\n",
    "fichiers_dans_dossier = os.listdir(dossier2)\n",
    "\n",
    "for nom_fichier in fichiers_dans_dossier:\n",
    "    chemin_complet = os.path.join(dossier2, nom_fichier)\n",
    "    if os.path.isfile(chemin_complet) and nom_fichier.endswith(\".txt\"):\n",
    "        with open(chemin_complet, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()\n",
    "            PB.append(contenu)\n",
    "\n",
    "\n",
    "dossier3 = \"plagitat_corpus/plagitat_corpus/PC\"\n",
    "PC = []\n",
    "\n",
    "fichiers_dans_dossier = os.listdir(dossier3)\n",
    "\n",
    "for nom_fichier in fichiers_dans_dossier:\n",
    "    chemin_complet = os.path.join(dossier3, nom_fichier)\n",
    "    if os.path.isfile(chemin_complet) and nom_fichier.endswith(\".txt\"):\n",
    "        with open(chemin_complet, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()\n",
    "            PC.append(contenu)\n",
    "\n",
    "\n",
    "dossier4 = \"plagitat_corpus/plagitat_corpus/PD\"\n",
    "PD = []\n",
    "\n",
    "fichiers_dans_dossier = os.listdir(dossier4)\n",
    "\n",
    "for nom_fichier in fichiers_dans_dossier:\n",
    "    chemin_complet = os.path.join(dossier4, nom_fichier)\n",
    "    if os.path.isfile(chemin_complet) and nom_fichier.endswith(\".txt\"):\n",
    "        with open(chemin_complet, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()\n",
    "            PD.append(contenu)\n",
    "\n",
    "\n",
    "dossier5 = \"plagitat_corpus/plagitat_corpus/PE\"\n",
    "PE = []\n",
    "\n",
    "fichiers_dans_dossier = os.listdir(dossier5)\n",
    "\n",
    "for nom_fichier in fichiers_dans_dossier:\n",
    "    chemin_complet = os.path.join(dossier5, nom_fichier)\n",
    "    if os.path.isfile(chemin_complet) and nom_fichier.endswith(\".txt\"):\n",
    "        with open(chemin_complet, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()\n",
    "\n",
    "            PE.append(contenu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de similarité pour le texte original et le texte des 5 étudiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1, sim2, sim3, sim4, sim5 = [], [], [], [], []\n",
    "\n",
    "for i in range(len(text_wikipedia)):\n",
    "    distance = Levenshtein.distance(text_wikipedia[i], PA[i])\n",
    "    similarity = 1 - (distance / max(len(text_wikipedia[i]), len(PA[i])))\n",
    "    sim1.append(similarity)\n",
    "\n",
    "    distance = Levenshtein.distance(text_wikipedia[i], PB[i])\n",
    "    similarity = 1 - (distance / max(len(text_wikipedia[i]), len(PB[i])))\n",
    "    sim2.append(similarity)\n",
    "\n",
    "    distance = Levenshtein.distance(text_wikipedia[i], PC[i])\n",
    "    similarity = 1 - (distance / max(len(text_wikipedia[i]), len(PC[i])))\n",
    "    sim3.append(similarity)\n",
    "\n",
    "    distance = Levenshtein.distance(text_wikipedia[i], PD[i])\n",
    "    similarity = 1 - (distance / max(len(text_wikipedia[i]), len(PD[i])))\n",
    "    sim4.append(similarity)\n",
    "\n",
    "    distance = Levenshtein.distance(text_wikipedia[i], PE[i])\n",
    "    similarity = 1 - (distance / max(len(text_wikipedia[i]), len(PE[i])))\n",
    "    sim5.append(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores de similarités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>sim4</th>\n",
       "      <th>sim5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254060</td>\n",
       "      <td>0.216899</td>\n",
       "      <td>0.484023</td>\n",
       "      <td>0.177580</td>\n",
       "      <td>0.157674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243553</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.216810</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>0.125119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752964</td>\n",
       "      <td>0.250847</td>\n",
       "      <td>0.270092</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>0.232543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.262840</td>\n",
       "      <td>0.273917</td>\n",
       "      <td>0.251259</td>\n",
       "      <td>0.472810</td>\n",
       "      <td>0.209970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.248870</td>\n",
       "      <td>0.223370</td>\n",
       "      <td>0.214977</td>\n",
       "      <td>0.269206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sim1      sim2      sim3      sim4      sim5\n",
       "0  0.254060  0.216899  0.484023  0.177580  0.157674\n",
       "1  0.243553  0.222222  0.216810  0.154091  0.125119\n",
       "2  0.752964  0.250847  0.270092  0.123188  0.232543\n",
       "3  0.262840  0.273917  0.251259  0.472810  0.209970\n",
       "4  0.335700  0.248870  0.223370  0.214977  0.269206"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer un dictionnaire avec les données\n",
    "data = {\n",
    "    'sim1': sim1,\n",
    "    'sim2': sim2,\n",
    "    'sim3': sim3,\n",
    "    'sim4': sim4,\n",
    "    'sim5': sim5,\n",
    "}\n",
    "\n",
    "# Créer le DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
